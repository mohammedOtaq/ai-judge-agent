import os
import json
from pathlib import Path

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
base = Path("ai_judge_agent")
pages = base / "pages"
base.mkdir(exist_ok=True)
pages.mkdir(parents=True, exist_ok=True)

# Ù…Ù„Ù app.py
with open(base / "app.py", "w", encoding="utf-8") as f:
    f.write("""
import streamlit as st
import json
import os
import openai
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def load_precedents(file_path="precedents.json"):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_case_to_json(case_data, file_path="judgments.json"):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            all_cases = json.load(f)
    else:
        all_cases = []
    all_cases.append(case_data)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(all_cases, f, ensure_ascii=False, indent=2)

def save_to_precedents_from_ai(case_id, summary, decision_text):
    new_entry = {
        "Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©": case_id,
        "Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø¶ÙŠØ©": "Ù…Ø¯Ù†ÙŠ Ø¬Ø²Ø¦ÙŠ",
        "Ø§Ù„Ù…ÙˆØ§Ø¯": ["742", "745", "267"],
        "Ø§Ù„ÙˆØµÙ": summary.strip(),
        "Ø§Ù„Ù‚Ø±Ø§Ø±": decision_text.split("Ø­ÙƒÙ…Øª Ø§Ù„Ù…Ø­ÙƒÙ…Ø©")[0].strip() if "Ø­ÙƒÙ…Øª Ø§Ù„Ù…Ø­ÙƒÙ…Ø©" in decision_text else decision_text[:200],
        "Ø§Ù„Ø­ÙŠØ«ÙŠØ§Øª": decision_text.strip(),
        "Ø§Ù„ÙƒÙ„Ù…Ø§Øª_Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©": ["GPT", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø¥ÙŠØ¬Ø§Ø±"]
    }

    file_path = "precedents.json"
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            precedents = json.load(f)
    else:
        precedents = []

    precedents.append(new_entry)

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(precedents, f, ensure_ascii=False, indent=2)

def ask_judge_agent(case_summary, previous_cases):
    context = ""
    for case in previous_cases[-3:]:
        context += f"\\n- Ø§Ù„Ø¯Ø¹ÙˆÙ‰ Ø±Ù‚Ù… {case['Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©']}, {case['Ø§Ù„ÙˆØµÙ']}, Ø§Ù„Ø­ÙƒÙ…: {case['Ø§Ù„Ù‚Ø±Ø§Ø±']}"

    prompt = f'''
Ø£Ù†Øª Ù‚Ø§Ø¶Ù Ù…Ø¯Ù†ÙŠ ØªØµØ¯Ø± Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù‚Ø§Ù†ÙˆÙ†ÙŠ ØµØ§Ø±Ù…ØŒ Ø¨Ø§Ù„Ø§Ø³ØªÙ†Ø§Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù‚ÙˆØ¯ ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.
Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø©:
{context}

Ø§Ù„Ù‚Ø¶ÙŠØ©:
{case_summary}

Ø±Ø¬Ø§Ø¡Ù‹ Ø£ØµØ¯ÙØ± Ø­ÙƒÙ…Ùƒ Ù…ØªØ¶Ù…Ù†Ù‹Ø§ Ø§Ù„Ù‚Ø±Ø§Ø± ÙˆØ§Ù„Ø­ÙŠØ«ÙŠØ§Øª Ø¨ØµÙŠØ§ØºØ© Ù‚Ø¶Ø§Ø¦ÙŠØ©.
'''
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}"

st.set_page_config(page_title="Ø§Ù„Ù‚Ø§Ø¶ÙŠ Ø§Ù„Ø°ÙƒÙŠ", layout="centered")
st.title("âš–ï¸ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙƒÙŠ")

case_id = st.text_input("Ø±Ù‚Ù… Ø§Ù„Ø¯Ø¹ÙˆÙ‰", "999/2025")
claim_amount = st.number_input("Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Ø¯Ø±Ù‡Ù…)", step=500.0)
documents = st.multiselect("Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©", ["Ø¹Ù‚Ø¯ Ø¥ÙŠØ¬Ø§Ø±", "ÙƒØ´Ù Ø­Ø³Ø§Ø¨", "ØªÙ‚Ø±ÙŠØ± Ø®Ø¨Ø±Ø©", "ÙˆØ§ØªØ³Ø§Ø¨"])
has_expert_report = "ØªÙ‚Ø±ÙŠØ± Ø®Ø¨Ø±Ø©" in documents
defendant_present = st.radio("Ù‡Ù„ Ø­Ø¶Ø± Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡ØŸ", ["Ù†Ø¹Ù…", "Ù„Ø§"]) == "Ù†Ø¹Ù…"

if st.button("Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø­ÙƒÙ…"):
    case_data = {
        "Ø±Ù‚Ù… Ø§Ù„Ø¯Ø¹ÙˆÙ‰": case_id,
        "Ø§Ù„Ù…Ø¨Ù„Øº": claim_amount,
        "Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª": documents,
        "Ø­Ø¶Ø± Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡": defendant_present,
        "ØªÙ‚Ø±ÙŠØ± Ø®Ø¨Ø±Ø©": has_expert_report,
        "Ø§Ù„Ù‚Ø±Ø§Ø±": f"Ø¥Ù„Ø²Ø§Ù… Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡ Ø¨Ø§Ù„Ù…Ø¨Ù„Øº {claim_amount} Ø¯Ø±Ù‡Ù… Ù…Ø¹ ÙØ§Ø¦Ø¯Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© 5%",
        "Ø§Ù„Ø­ÙŠØ«ÙŠØ§Øª": "Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ØŒ ÙˆØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø®Ø¨Ø±Ø©ØŒ ÙˆØºÙŠØ§Ø¨ Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡ØŒ ØªØ±Ù‰ Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø¥Ù„Ø²Ø§Ù…Ù‡ Ø¨Ø§Ù„Ù…Ø¨Ù„Øº."
    }
    save_case_to_json(case_data)
    st.success("âœ… ØªÙ… Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø­ÙƒÙ… ÙˆØ­ÙØ¸Ù‡.")
    st.json(case_data)

st.markdown("---")
st.subheader("ğŸ¤– Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ø¶ÙŠ Ø§Ù„Ø°ÙƒÙŠ (GPT)")

if st.button("Ø§Ø³ØªØ´Ø§Ø±Ø© AI Agent"):
    summary = f\"""Ø±Ù‚Ù… Ø§Ù„Ø¯Ø¹ÙˆÙ‰: {case_id}
Ø§Ù„Ù…Ø¨Ù„Øº: {claim_amount} Ø¯Ø±Ù‡Ù…
Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª: {', '.join(documents)}
Ø­Ø¶ÙˆØ± Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡: {"Ù†Ø¹Ù…" if defendant_present else "Ù„Ø§"}
ØªÙ‚Ø±ÙŠØ± Ø®Ø¨Ø±Ø©: {"Ù…ÙˆØ¬ÙˆØ¯" if has_expert_report else "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}\"""
    precedents = load_precedents()
    result = ask_judge_agent(summary, precedents)
    st.text_area("Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ù‚ØªØ±Ø­:", result, height=300)

    if st.button("ğŸ“Œ Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚"):
        save_to_precedents_from_ai(case_id, summary, result)
        st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø°ÙƒÙŠ ÙƒØ³Ø§Ø¨Ù‚Ø© Ù‚Ø¶Ø§Ø¦ÙŠØ©.")
""")

# ØµÙØ­Ø© Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚
with open(pages / "1_ğŸ“š_Ø¹Ø±Ø¶_Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚_Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©.py", "w", encoding="utf-8") as f:
    f.write("""
import streamlit as st
import json
import os

st.set_page_config(page_title="Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©", layout="centered")
st.title("ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©")

def load_precedents(file_path="precedents.json"):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

precedents = load_precedents()
if not precedents:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³ÙˆØ§Ø¨Ù‚ Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø¹Ø¯.")
else:
    all_keywords = set(kw for c in precedents for kw in c.get("Ø§Ù„ÙƒÙ„Ù…Ø§Øª_Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©", []))
    keyword = st.selectbox("ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©", ["Ø§Ù„ÙƒÙ„"] + sorted(all_keywords))

    filtered = []
    for c in precedents:
        if keyword == "Ø§Ù„ÙƒÙ„" or keyword in c.get("Ø§Ù„ÙƒÙ„Ù…Ø§Øª_Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©", []):
            filtered.append(c)

    st.markdown(f"### Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {len(filtered)}")
    for case in filtered:
        with st.expander(f"ğŸ“ {case['Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©']} â€“ {case['Ø§Ù„ÙˆØµÙ']}"):
            st.write(f"**Ø§Ù„Ù‚Ø±Ø§Ø±:** {case['Ø§Ù„Ù‚Ø±Ø§Ø±']}")
            st.text_area("Ø§Ù„Ø­ÙŠØ«ÙŠØ§Øª:", case["Ø§Ù„Ø­ÙŠØ«ÙŠØ§Øª"], height=200)
""")

# Ù…Ù„ÙØ§Øª JSON
for filename in ["judgments.json", "precedents.json"]:
    with open(base / filename, "w", encoding="utf-8") as f:
        json.dump([], f, ensure_ascii=False, indent=2)

# Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ¦Ø©
with open(base / ".env", "w", encoding="utf-8") as f:
    f.write("OPENAI_API_KEY=\n")

# Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
with open(base / "requirements.txt", "w", encoding="utf-8") as f:
    f.write("streamlit\nopenai\npython-dotenv\nfpdf\nrequests")

print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ ai_judge_agent Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰")
